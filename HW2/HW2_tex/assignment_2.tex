%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{mathtools} %More math! (For dscases)
\usepackage{hyperref} %HTML package
\usepackage{pgfplots} %Makes plots in LaTeX
\usepackage{tikz} %Also tikz?
\usepackage{bm} %makes vectors bold
\usepackage{bbm} %Blackboard bold 1
\usepgfplotslibrary{fillbetween}%Let's me fill between named plots
\usepackage{graphicx} %import pics

\usepackage[noend]{algpseudocode} %Algorithms
\usepackage{algorithm}

\graphicspath{ {Python_figs/} }
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{ \normalfont\scshape} % Make all sections the default font and small caps


\renewcommand{\thesubsection}{\alph{subsection}} %Make subsections start with letters

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

\usepackage{listings}
\lstset{language=Python}


%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	Assignment 2}

\author{Benjamin Jakubowski} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\section{Recurrences}

First, recall the master theorem provides bounds for recurrences of the form
\[T(n) = a T\left(\frac{n}{b}\right) + f(n)\]

\subsection{$T(n) = 4 T\left(\frac{n}{3}\right) + n$}

In this problem, $a = 4, b = 3, $ and $f(n) = n$.

Since $f(n) = n = O(n^{log_{3} 4 - \epsilon})$, then $T(n) = \Theta(n^{log_{3} 4})$ (by master theorem case one). We proceed to prove this bound using substitution:

Assume $T(k) \leq c_1 k^{log_3 4} - c_2 k$ for $k < n$. Now consider $T(n) = 4 T\left(\frac{n}{3}\right) + n$. Then
\begin{align*}
T(N) &= 4 T\left(\frac{n}{3}\right) + n\\
	&\leq 4 \left[c_1 \left(\frac{n}{3}\right)^{log_3 4} - c_2 \left(\frac{n}{3}\right)\right] + n\\
	&= c_1 n^{log_3 4} - \frac{4}{3} c_2\cdot n+ n\\
	&= c_1 n^{log_3 4} - \left[\frac{4}{3} c_2 - 1\right] n
\end{align*}

Then to conclude the proof, we must show 
\begin{align*} 
c_1 n^{log_3 4} - \left[\frac{4}{3} c_2 - 1\right] n &\leq c_1 n^{log_3 4} - \left[\frac{4}{3} c_2 - 1\right] n \\
\implies \qquad{} \frac{4}{3} c_2 - 1 \geq c_2\\
\implies \qquad{} 1 \leq \frac{1}{3} c_2\\
\implies \qquad{} 3 \leq c_2
\end{align*}

Thus, having shown the bound holds for all $c_2\geq 3$, we've shown $T(n) = \Theta(n^{log_{3} 4})$.

\subsection{$T(n) = 4 T\left(\frac{n}{2}\right) + n^2$}

In this problem, $a = 4, b = 2, $ and $f(n) = n^2$.

Since $f(n) = n^2 = \Theta(n^{log_{2} 4 }) = \Theta(n^2)$, then $T(n) = \Theta(n^{log_{2} 4} \log n) = \Theta(n^2 \log n)$ (by master theorem case two). We proceed to prove this bound using substitution:

Assume $T(k) \leq d k^{2} \log k$ for $k < n$. Now consider $T(n) = 4 T\left(\frac{n}{2}\right) + n^2$. Then
\begin{align*}
T(N) &= 4 T\left(\frac{n}{2}\right) + n^2\\
	&\leq 4 \left[d \left(\frac{n}{2}\right)^{2} \log \left(\frac{n}{2}\right)\right] + n^2\\
	&= d n^2 \log n - d n^2 \log 2 + n^2 \\
	&= d n^2 \log n - (d - 1)n^2 \\
	&\leq d n^2 \log n \qquad{} \textrm{ if } d\geq1
\end{align*}

Thus, having shown the bound holds for all $d\geq 1$, we've shown $T(n) = \Theta(n^2 \log n)$.

\subsection{$T(n) = 4 T\left(\frac{n}{2}\right) + n^2\log n$}

In this problem, $a = 4, b = 2, $ and $f(n) = n^2\log n$.

Next, note $n^{\log_b a} = n^{\log_2 4} = n^2$. Then, while $f(n) = n^2 \log n$ is asymptotically larger than $n^2$, it is not polynomially larger. Thus, the master theorem is not applicable (and, per the instructions in the class forum, the solution is not found).

%----------------------------------------------------------------------------------------
%	PROBLEM 2
%----------------------------------------------------------------------------------------

\section{Exact solution of recurrence}

We aim to find the exact solution of the recurrence
\[
T(n) =
\begin{cases}
c & \qquad{} \textrm{if } n=0\\
aT(n-1) + k & \qquad{} \textrm{if } n>0
\end{cases}
\]
\textbf{Solution:}
The solution is
\[T(n) = \sum_{i = 0}^{n-1} a^i \cdot k + a^n \cdot c\]

\textbf{Proof:}

We prove by induction- just to build insight, we prove few additional base cases.

First, when $n = 0, T(n) = c$.
When $n = 1$,
\[T(1) = a \cdot T(0) + k = a \cdot c + k\]
When $n = 2$
\[T(2) = a\cdot T(1) + k = a\cdot(a \cdot c + k) + k = a\cdot k + k + a^2 c\]

Thus, we hypothesize $T(n) = a^{n-1}k + a^{n-2}k + \cdots + a^{0}k + a^n c$.

Formally, assume for $n$
\[T(n) = \sum_{i = 0}^{n-1} a^i \cdot k + a^n \cdot c\]

Then consider $T(n+1)$:
\begin{align*}
T(n+1) &= a T(n) + k \\
	   &= a \left[\sum_{i = 0}^{n-1} a^i \cdot k + a^n \cdot c\right] + k \\
	   &= \left(\sum_{i = 0}^{n-1} a^{i+1} \cdot k\right) + k + a^{n+1} \cdot c \\
	   &= \left(\sum_{i = 1}^{n} a^i \cdot k\right) + a^0 k + a^{n+1} \cdot c \\
	   &= \left(\sum_{i = 0}^{(n+1)-1} a^i \cdot k\right) + a^{n+1} \cdot c
\end{align*}


%----------------------------------------------------------------------------------------
%	PROBLEM 3
%----------------------------------------------------------------------------------------

\section{Iterative binary search}

Pseudocode for iterative binary search is given in Algorithm 1.

\begin{algorithm}\small
\caption{Iterative binary search}
\label{itbs}
\begin{algorithmic}[1]
\Function{iterative\_binary\_search}{$A$, target}
	\State lower\_index = $0$
	\State upper\_index = len($A$) - 1
	\While {upper\_index > lower\_index}
		\State middle\_index = (lower\_index + upper\_index)/2
		\If {$A$[middle\_index] < target}
			\State lower\_index = middle\_index+1
		\ElsIf {$A$[middle\_index] > target}
			\State upper\_index = middle\_index-1
		\Else:
			\State \Return middle\_index
		\EndIf
	\EndWhile
	\If {upper\_index == lower\_index}
		\If {$A$[lower\_index] == target}
			\State \Return lower\_index
		\Else: 
			\State \Return "Target not in array"
		\EndIf
	\Else:
		\State \Return "Target not in (empty) array."
	\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

Now we prove the correctness of our algorithm using a loop invariant. First, for the sake of notation, we'll refer to $target$ as $t$, $lower\_index$ as $l$, $middle\_index$ as $m$, and $upper\_index$ as $u$. We prove the correctness through two cases: $t$ in $A$ and $t$ not in $A$. First, if $t$ is in $A$, we use the following loop invariant: at the start of each iteration of the while loop, if $t$ is in $A$, then $t$ is in the subarray $A[i, u]$.
\begin{itemize}
\item \textbf{Initialization}: If $t$ is in $A$, then prior to the first iteration of the loop $t$ is in $A[l, u]$ since $A[l, u] = A$.
\item \textbf{Maintenance}: Now assume the invariant is true before an iteration of the loop. Then (assuming the loop doesn't terminate with the correct solution $m$) note the body of the loop either changes the value of $u$ or $l$; in either case, the change ensures $A[l,u]$ still contains $t$ (because of the conditions in the \textbf{if} and \textbf{else if} blocks on line 6 and 8).
\item \textbf{Termination}: Now note the loop terminates in one of two ways:
\begin{itemize}
\item \textbf{Loop terminates due to condition}: In this case, the loop terminates when $l = u$. But then, since $t$ is in $A[l,u]$, $l = u$ implies $A[l,u]$ contains a single element- namely $t$. Thus, returning $l$ in line 12 returns the correct index of $t$ in the array.
\item \textbf{Function returns}: In this case, the function returns (from line 10) with the correct value, since the \textbf{else} statement only evaluates when $t = A[m]$.
\end{itemize}
\end{itemize}

Finally, to complete the proof, let's consider the case when $A$ does not contain $t$. Then the algorithm is clearly correct, since either
\begin{itemize}
\item \textbf{$A$ is the empty array}: In this case, the while loop is not executed (since $u = -1 < 0 = l$), and control jumps from line 4 to line 14, returning the string indicating the target is not in the empty array.
\item \textbf{$A$ is non-empty}: In this case, the while loop is executed, but clearly $A[m] \ne t$; hence the loop terminates exactly when $u = l$ (note the loop will terminate, since $u - l$ is strictly decreasing with each iteration of the loop). Thus, after the loop terminates, the program evaluates the \textbf{else} block on line 13, returning the target is not in the array.
\end{itemize}

Finally, note the worst case runtime of this implementation of binary search is when $t$ is not in $A$. Then the 
\textbf{while} loop is executed $O(\log(n))$ times, so the worst-case running time is $O(\log(n))$.

%----------------------------------------------------------------------------------------
%	PROBLEM 4
%----------------------------------------------------------------------------------------

\section{Recursive binary search}

Pseudocode for recursive binary search is given in Algorithm 2. Note each call to the function spans a single recursive call (with $1/2 (u_0 - l_0) \approx u_1 - l_1$). Otherwise the function's runtime is $O(1)$ (all since all other statements run in constant time). Thus, our recurrence is $T(n) = T\left(\frac{n}{2}\right) + c$. sThen, by the master theorem case 2, we have
\[f(n) = c = \Theta(1) = \Theta(n^{0}) = \Theta(n^{log_2 1}) = \Theta(n^{log_b a})\]
so
\[T(n) = \Theta(n^{log_2 1} \log n) =  \Theta( \log n) \]

\begin{algorithm}\small
\caption{Recursive binary search}
\label{itbs}
\begin{algorithmic}[1]
\Function{Rec\_binary\_search}{$A$, target, lower\_index = None, upper\_index = None}
	\If {lower\_index is none}
		\State lower\_index = 0
	\EndIf
	\If {upper\_index is none}
		\State upper\_index = len($A$) - 1
	\EndIf
	
	\If {upper\_index > lower\_index}
		\State middle\_index = (lower\_index + upper\_index)/2
		\If {$A$[middle\_index] < target}
			\State \Return Recursive\_binary\_search($A$, target, middle\_index+1, upper\_index)
		\ElsIf {$A$[middle\_index] > target}
			\State \Return Recursive\_binary\_search($A$, target, lower\_index, middle\_index-1)
		\Else:
			\State \Return middle\_index
		\EndIf
	\ElsIf {upper\_index == lower\_index}
		\If {$A$[lower\_index] == target}
			\State \Return lower\_index
		\Else: 
			\State \Return "Target not in array"
		\EndIf
	\Else:
		\State \Return "Target not in (empty) array."
	\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

%----------------------------------------------------------------------------------------
%	PROBLEM 5
%----------------------------------------------------------------------------------------

\section{Counting inversions with merge sort}

Pseudocode for counting inversions using a modification of merge sort is given in Algorithm 3. Note the only real change (beside minor changes in function signatures) between this inversion counting algorithm and vanilla merge sort is \textbf{Line 17}, where we increment the inversion count by the number of elements remaining in $A$ if we append an element from $B$ before array $A$ is empty. This is a constant-time addition to the algorithm. \\

Since merge sort has a worst-case running time of $O(n \log n)$, and we are only adding constant time operations to the algorithm, the worst-case running time of our inversion counting algorithm is also $O(n \log n)$. To be more rigorous, we can formulate and solve a recurrence. First, note \texttt{inversion\_count\_merge}'s worst-case runtime is $O(n)$; in addition, the other (non-recursive) operations in \texttt{inversion\_count\_merge\_sort} run in constant time\footnote{More precisely, the non-recursive operations in \texttt{inversion\_count\_merge\_sort} could be implemented in constant time. Note the outlined approach using list slicing is suboptimal. An improved version of the pseudocode would not use list slicing, which is not $O(1)$, and instead change the function signature to include parameters for the lower and upper indices into the original array}. Thus, \texttt{inversion\_count\_merge\_sort} runtime is $T(n) = 2\cdot T\left(\frac{n}{2}\right) + c\cdot n$. Now we apply the master theorem:
\[f(n) = c\cdot n =  \Theta(n) =  \Theta(n^1) = \Theta(n^{\log_2 2}) = \Theta(n^{\log_b a})\]
Thus, by master theorem case 2,
\[T(n) = \Theta(n^{\log_b a}\log n) = \Theta(n \log n)\]


\begin{algorithm}\small
\caption{Counting inversions}
\label{itbs}
\begin{algorithmic}[1]
\Function{inversion\_count\_merge}{$A$, $B$, count = 0}
	\State n = len($A$) + len($B$)
	\State $A$.append(`end')
	\State $B$.append(`end')
	\State merged = []
	\For {i in $[0, \cdots n-1]$}
		\If {len($A$) == 1}
			\State merged.extend($B$[0:-1])
			\State \Return merged, count
		\ElsIf {len($B$) == 1}
			\State merged.extend($A$[0:-1])
			\State \Return merged, count
		\ElsIf {$A[0] \leq B[0]$}
			\State merged.append($A$.pop(0))
		\Else
			\State merged.append($B$.pop(0))
			\State count += len(A) - 1
		\EndIf
	\EndFor
\EndFunction
\Function{inversion\_count\_merge\_sort}{$A$}	
	\If {len$(A)>1$}
		\State $n$ = len($A$)
		\State $mid$ = $n$/2
		\State $L$ = $A[0:mid]$
		\State $R$ = $A[mid:n]$
		\State $L$\_sorted, $L$\_count = inversion\_count\_merge\_sort($L$)
		\State $R$\_sorted, $R$\_count = inversion\_count\_merge\_sort($R$)
		\State \Return inversion\_count\_merge($L$\_sorted, $R$\_sorted, $L$\_count + $R$\_count)
	\Else
		\State \Return $A$, 0
	\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}
%----------------------------------------------------------------------------------------

\end{document}